{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff25649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime as dt\n",
    "import random\n",
    "import copy \n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('data/keiba_feature_preprocessed_all.csv')\n",
    "sinba = list(map(lambda x: ('新馬' in x) if not pd.isna(x) else True, df['race_name'].to_numpy()))\n",
    "delete_index = df.index[sinba | (df[\"course\"]=='障') | (df[\"rank\"]==\"中止\") | (df[\"rank\"]=='取消') | (df[\"rank\"]==\"失格\") | (df['rank']=='除外') | pd.isna(df['rank'])]\n",
    "df.drop(delete_index, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b66edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name in df['race_name'].unique():\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d411e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\n",
    "    'field', \n",
    "    'race_name', \n",
    "    'course', \n",
    "    'gender',  \n",
    "    #'trainerA', \n",
    "    'horse_name',\n",
    "    'trainerB', \n",
    "    'jackie', \n",
    "    'cond', \n",
    "    'turn',\n",
    "    'weather', \n",
    "    'wakuban', \n",
    "    #'umaban', \n",
    "    'age', \n",
    "    'pre_rank', \n",
    "    'pre2_rank', \n",
    "    'pre3_rank', \n",
    "    #'pre4_rank', \n",
    "    #'pre5_rank',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f76cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_columns = [\n",
    "    'head_count', \n",
    "    'weight', \n",
    "    'c_weight',\n",
    "    'j_weight', \n",
    "    'distance',\n",
    "    'pre_weight', \n",
    "    'sum_prize', \n",
    "    'pre_speed', \n",
    "    'pre2_speed',\n",
    "    'pre3_speed', \n",
    "    #'pre4_speed', \n",
    "    #'pre5_speed', \n",
    "    'from_last_day', \n",
    "    'rentai',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3454f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical] = df[categorical].fillna('nan').astype(str)\n",
    "le=LabelEncoder()\n",
    "keiba_categorical = df[categorical].apply(le.fit_transform)\n",
    "keiba_categorical = keiba_categorical.rename(columns={c: c+'_c' for c in categorical})\n",
    "df = pd.concat([df, keiba_categorical],axis=1)\n",
    "# 変換前と不要な列を削除\n",
    "df.drop(columns=categorical, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626a89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df[scaling_columns] = df[scaling_columns].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[scaling_columns])\n",
    "df[scaling_columns] = pd.DataFrame(scaler.transform(df[scaling_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7eb4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['date'] > df['date'].unique()[-1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b06ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1331b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        super().__init__()\n",
    "        self.df = dataframe\n",
    "        self.race_list = dataframe['race_num'].unique()\n",
    "        #self.embedding = nn.Embedding(len(df['horse_name_c'].unique()), 128)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        race_name = self.race_list[i]\n",
    "        df = self.df[self.df['race_num'] == race_name].sample(frac=1)\n",
    "        df_x_c = df[[c+'_c' for c in categorical]].to_numpy()\n",
    "        df_x_f = df[scaling_columns].to_numpy()\n",
    "        df_odds = df['odds'].to_numpy()\n",
    "        df_y = df['rank'].to_numpy()\n",
    "        #horse = torch.tensor(df['horse_name_c'].to_numpy())\n",
    "        #x = embedding(horse)\n",
    "        #x = torch.cat([x, torch.zeros(18-x.shape[0], 128)], dim=0)\n",
    "        #y = df['rank'].to_numpy()\n",
    "        #y = (y==1).astype(int)\n",
    "        #y = np.append(y, np.zeros(18-y.shape[0]))\n",
    "        #y = y[None]\n",
    "        #y = torch.tensor(y)\n",
    "        \n",
    "        return df_x_c, df_x_f, df_y, df_odds\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.race_list)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        xcs, xfs, ys, odds = [], [], [], []\n",
    "        for xc, xf, y, odd in batch:\n",
    "            \n",
    "            zero = np.zeros((18-len(xc), len(xc[0])))\n",
    "            xc = np.concatenate([xc, zero], axis=0)\n",
    "            \n",
    "            xcs.append(xc)\n",
    "            \n",
    "            zero = np.zeros((18-len(xf), len(xf[0])))\n",
    "            xf = np.concatenate([xf, zero], axis=0)\n",
    "            \n",
    "            xfs.append(xf)\n",
    "            \n",
    "            \n",
    "            y_numpy = y.astype(int)\n",
    "            ys.append(torch.from_numpy(y_numpy))\n",
    "            \n",
    "            odds.append(torch.from_numpy(odd))\n",
    "        xcs = np.stack(xcs, axis=0)\n",
    "        xfs = np.stack(xfs, axis=0)\n",
    "        return torch.from_numpy(xcs).long(), torch.from_numpy(xfs), ys, odds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1607e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6dbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_2020 = dt(2020, 1, 1)\n",
    "date_2021 = dt(2021, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2d262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['date'] < date_2020]\n",
    "df_val = df[(date_2020 < df['date']) & (df['date'] < date_2021)]\n",
    "df_test = df[date_2021 < df['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25dea38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keiba_train = KDataset(df_train)\n",
    "keiba_val = KDataset(df_val)\n",
    "keiba_test = KDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032add6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keiba_trainloader = DataLoader(keiba_train, shuffle=True, batch_size=240, collate_fn=keiba_train.collate_fn)\n",
    "keiba_valloader = DataLoader(keiba_val, shuffle=False, batch_size=240, collate_fn=keiba_val.collate_fn)\n",
    "keiba_testloader = DataLoader(keiba_test, shuffle=False, batch_size=240, collate_fn=keiba_test.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566c6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b7dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f62203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7411b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ed339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1ea3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a38381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3b162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Classic Transformer that both encodes and decodes.\n",
    "    \n",
    "    Prediction-time inference is done greedily.\n",
    "    NOTE: start token is hard-coded to be 0, end token to be 1. If changing, update predict() accordingly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nhead=4, num_layers=4, embedding_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Parameters\n",
    "        #categorical = ['field', 'race_name', 'course', 'horse_name', 'gender', 'trainerA', 'trainerB', 'jackie', 'cond', 'turn', 'weather', 'wakuban', 'umaban', 'age']\n",
    "        self.categorical_list = [c+'_c' for c in categorical]\n",
    "        self.feature_list = scaling_columns\n",
    "        self.dim = embedding_dim * len(self.categorical_list) + len(self.feature_list)\n",
    "        dim_feedforward = self.dim\n",
    "            \n",
    "        # Embedding part\n",
    "        self.embeddings = nn.ModuleDict({name: nn.Embedding(len(df[name].unique()), embedding_dim) for name in self.categorical_list})\n",
    "        # Encoder part\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(d_model=self.dim, nhead=nhead, dim_feedforward=dim_feedforward),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Decoder part\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=nn.TransformerDecoderLayer(d_model=self.dim, nhead=nhead, dim_feedforward=dim_feedforward),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(self.dim, 1)\n",
    "\n",
    "        # It is empirically important to initialize weights properly\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.fc.bias.data.zero_()\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "      \n",
    "    def forward(self, xcs, xfs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input\n",
    "            dfs: list of dataframe\n",
    "        Output\n",
    "            (B, C, Sy) logits\n",
    "        \"\"\"\n",
    "        x = self.embedding(xcs, xfs)\n",
    "        encoded_x = self.encode(x)  # (member, B, E)\n",
    "        output = self.decode(encoded_x)  # (B, member)\n",
    "        return output  # (B, member)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input\n",
    "            x: (B, member, E)\n",
    "        Output\n",
    "            (member, B, E)\n",
    "        \"\"\"\n",
    "        \n",
    "        x = x.permute(1, 0, 2)  # (member, B, E)\n",
    "        #x = self.embedding(x) * math.sqrt(self.dim)  # (Sx, B, E)\n",
    "        #x = self.pos_encoder(x)  # (Sx, B, E)\n",
    "        \n",
    "        x = self.transformer_encoder(x)  # (member, B, E)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, encoded_x):\n",
    "        \"\"\"\n",
    "        Input\n",
    "            encoded_x: (member, B, E)\n",
    "        Output\n",
    "            (B, member) logits\n",
    "        \"\"\"\n",
    "        #print(self.m)\n",
    "        encoded_x = encoded_x.permute(1, 0, 2) # (B, member, E)\n",
    "        #print(encoded_x.shape)\n",
    "        output = self.fc(encoded_x)  # (B, member, 1)\n",
    "        output = output.squeeze(2)\n",
    "        return output\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Method to use at inference time. Predict y from x one token at a time. This method is greedy\n",
    "        decoding. Beam search can be used instead for a potential accuracy boost.\n",
    "        Input\n",
    "            x: (B, Sx) with elements in (0, C) where C is num_classes\n",
    "        Output\n",
    "            (B, C, Sy) logits\n",
    "        \"\"\"\n",
    "        encoded_x = self.encode(x)\n",
    "        \n",
    "        output = self.decode(encoded_x)\n",
    "        return output\n",
    "    \n",
    "    def fullfill(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            feature_num = 1\n",
    "            return torch.cat([x, torch.zeros(18-len(x)).cuda()], dim=0)\n",
    "        else:\n",
    "            feature_num = x.shape[1]\n",
    "        return torch.cat([x, torch.zeros(18-len(x), feature_num).cuda()], dim=0)\n",
    "    \n",
    "    def embedding(self, xcs, xfs):\n",
    "        \n",
    "        category_list = []\n",
    "        for i, name in enumerate(self.categorical_list):\n",
    "            xc = self.embeddings[name](xcs[:, :, i])\n",
    "            category_list.append(xc)\n",
    "        categorical_x = torch.cat(category_list, dim=2) #bs, seq, features\n",
    "        x = torch.cat([categorical_x, xfs*10], dim=2)\n",
    "        \n",
    "        return x.cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073e4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a547e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = embedding_dim * len(categorical) + len(scaling_columns)\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba53d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(nhead=1, num_layers=4, embedding_dim=embedding_dim)\n",
    "model.cuda()\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none') #nn.CrossEntropyLoss() #\n",
    "#optimizer = torch.optim.Adam(model.parameters() , lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e0b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters() , lr=1e-3)\n",
    "val_best = 1e9\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29cd26e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th 0.0 recovery 3.693236714975845, hit 68.0, cost 4140.0, accuracy 0.01642512157559395\n",
      "th 0.1 recovery 5.743801652892562, hit 68.0, cost 2662.0, accuracy 0.025544703006744385\n",
      "th 0.2 recovery 11.797839506172837, hit 68.0, cost 1296.0, accuracy 0.05246913433074951\n",
      "th 0.3 recovery 25.740740740740737, hit 68.0, cost 594.0, accuracy 0.11447811126708984\n",
      "th 0.4 recovery 51.655405405405396, hit 68.0, cost 296.0, accuracy 0.22972972691059113\n",
      "th 0.5 recovery 62.920353982300895, hit 65.0, cost 226.0, accuracy 0.28761062026023865\n",
      "th 0.6 recovery 73.80952380952381, hit 50.0, cost 147.0, accuracy 0.3401360511779785\n",
      "th 0.7 recovery 98.00000000000001, hit 17.0, cost 40.0, accuracy 0.42500001192092896\n",
      "th 0.8 recovery 0.0, hit 0.0, cost 1.000000013351432e-10, accuracy 0.0\n",
      "th 0.9 recovery 0.0, hit 0.0, cost 1.000000013351432e-10, accuracy 0.0\n",
      "tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "th 0.0 recovery 3.667486674866748, hit 78.0, cost 4878.0, accuracy 0.015990160405635834\n",
      "th 0.1 recovery 6.183892153473901, hit 78.0, cost 2893.0, accuracy 0.026961632072925568\n",
      "th 0.2 recovery 12.926300578034681, hit 78.0, cost 1384.0, accuracy 0.05635838210582733\n",
      "th 0.3 recovery 24.241192411924118, hit 78.0, cost 738.0, accuracy 0.10569106042385101\n",
      "th 0.4 recovery 46.83246073298429, hit 78.0, cost 382.0, accuracy 0.2041884809732437\n",
      "th 0.5 recovery 63.4065934065934, hit 76.0, cost 273.0, accuracy 0.27838829159736633\n",
      "th 0.6 recovery 61.047120418848166, hit 57.0, cost 191.0, accuracy 0.29842931032180786\n",
      "th 0.7 recovery 72.76923076923076, hit 23.0, cost 65.0, accuracy 0.35384616255760193\n",
      "th 0.8 recovery 60.0, hit 1.0, cost 3.0, accuracy 0.3333333432674408\n",
      "th 0.9 recovery 0.0, hit 0.0, cost 1.000000013351432e-10, accuracy 0.0\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "th 0.0 recovery 3.837837837837838, hit 113.0, cost 6660.0, accuracy 0.016966966912150383\n",
      "th 0.1 recovery 7.143655673560649, hit 113.0, cost 3578.0, accuracy 0.03158188983798027\n",
      "th 0.2 recovery 12.318072289156627, hit 113.0, cost 2075.0, accuracy 0.054457832127809525\n",
      "th 0.3 recovery 22.342657342657343, hit 113.0, cost 1144.0, accuracy 0.09877622127532959\n",
      "th 0.4 recovery 41.225806451612904, hit 113.0, cost 620.0, accuracy 0.18225806951522827\n",
      "th 0.5 recovery 64.38287153652394, hit 113.0, cost 397.0, accuracy 0.2846347689628601\n",
      "th 0.6 recovery 66.14886731391584, hit 96.0, cost 309.0, accuracy 0.3106796145439148\n",
      "th 0.7 recovery 64.52991452991454, hit 41.0, cost 117.0, accuracy 0.3504273593425751\n",
      "th 0.8 recovery 54.285714285714285, hit 5.0, cost 14.0, accuracy 0.3571428656578064\n",
      "th 0.9 recovery 0.0, hit 0.0, cost 1.000000013351432e-10, accuracy 0.0\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "models4 = []\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    for i, (xcs, xfs, ys, odds) in enumerate(keiba_trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xcs.cuda(), xfs.cuda())\n",
    "        #y_true = torch.tensor([y.min(dim=0)[1] for y in ys])\n",
    "        th = random.choice([1, 2, 3])\n",
    "        th = 3\n",
    "        y_true = torch.stack([torch.cat([(y<=th).long(), torch.zeros(18-len(y))], dim=0) for y in ys], dim=0).cuda()\n",
    "        y_1st = torch.stack([torch.cat([(y<=1).long(), torch.zeros(18-len(y))], dim=0) for y in ys], dim=0).cuda()\n",
    "        \n",
    "        loss = criterion(output, y_true)\n",
    "        odds = torch.stack([torch.cat([odd, torch.ones(18-len(odd))], dim=0) for odd in odds], dim=0).cuda().float()\n",
    "        odds = torch.nan_to_num(odds)\n",
    "        odds = torch.where(y_true==1, torch.sqrt(odds), torch.tensor([1.]).cuda())\n",
    "        #odds = torch.where(y_true==1, torch.tensor([2.]).cuda(), torch.tensor([1.]).cuda())\n",
    "        #loss = (loss * (odds))\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        \n",
    "        print(f'{i} / {len(keiba_trainloader)} {loss.item()}', end='\\r')\n",
    "        loss.backward()\n",
    "        #print(loss.item())\n",
    "        optimizer.step()\n",
    "    test_scores = []\n",
    "    win_flags = []\n",
    "    odds_list = []\n",
    "    model.eval()\n",
    "    dloader = keiba_valloader\n",
    "    for i, (xcs, xfs, ys, odds) in enumerate(dloader):\n",
    "        print(f'{i} / {len(dloader)}', end='\\r')\n",
    "        output = model(xcs.cuda(), xfs.cuda())\n",
    "        output = torch.sigmoid(output)\n",
    "        test_scores.append(output)\n",
    "        y_true = torch.tensor([y.min(dim=0)[1].item() for y in ys]).cuda()\n",
    "        y_onehot = F.one_hot(y_true, 18).float()\n",
    "        win_flags.append(y_onehot)\n",
    "        odds = torch.stack([torch.cat([odd, 100*torch.ones(18-len(odd))], dim=0) for odd in odds], dim=0)\n",
    "        \n",
    "        odds_list.append(odds)\n",
    "        \n",
    "    test_scores = torch.cat(test_scores, dim=0)\n",
    "    win_flags = torch.cat(win_flags, dim=0)\n",
    "    odds_list = torch.cat(odds_list, dim=0).cuda()\n",
    "    odds_list = torch.nan_to_num(odds_list)\n",
    "    thresh = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "    for th in thresh:\n",
    "        gap = (torch.sort(test_scores, dim=1)[0][:, -1] - torch.sort(test_scores, dim=1)[0][:, -2]) > 0.2\n",
    "        gap = gap.unsqueeze(1)\n",
    "        max_score = test_scores.max(dim=1)[0].unsqueeze(1)\n",
    "        buy_flags = (test_scores > th) * gap #* F.one_hot(odds_list.min(dim=1)[1], 18)#* (odds_list > 3)\n",
    "        win = (odds_list * (test_scores >= max_score) * buy_flags * win_flags).sum()\n",
    "        hit = ((test_scores >= max_score) * buy_flags * win_flags).sum()\n",
    "        cost = buy_flags.sum() + 1e-10\n",
    "        print(f'th {th} recovery {win/cost*100}, hit {hit}, cost {cost}, accuracy {hit/cost}')\n",
    "    \n",
    "    val_loss = 0\n",
    "    count = 0\n",
    "    for i, (xcs, xfs, ys, odds) in enumerate(keiba_valloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xcs.cuda(), xfs.cuda())\n",
    "        #y_true = torch.tensor([y.min(dim=0)[1] for y in ys])\n",
    "        th = random.choice([1, 2, 3])\n",
    "        th = 1\n",
    "        y_true = torch.stack([torch.cat([(y<=th).long(), torch.zeros(18-len(y))], dim=0) for y in ys], dim=0).cuda()\n",
    "        \n",
    "        loss = criterion(output, y_true)\n",
    "        count += loss.shape.numel()\n",
    "        loss = loss.sum()\n",
    "        val_loss += loss\n",
    "    val_loss /= count\n",
    "    print(val_loss)\n",
    "    if val_loss < val_best:\n",
    "        val_best = val_loss\n",
    "        model_best = copy.deepcopy(model)\n",
    "    models4.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d060d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "96595a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models0[2] #0.8\n",
    "#model = models1[1] #0.7\n",
    "#model = models2[0] #0.7\n",
    "model = models3[2] #0.7\n",
    "#model = models4[1] 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "8f9248f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 / 13\r"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "win_flags = []\n",
    "odds_list = []\n",
    "model.eval()\n",
    "dloader = keiba_testloader\n",
    "for i, (xcs, xfs, ys, odds) in enumerate(dloader):\n",
    "    print(f'{i} / {len(dloader)}', end='\\r')\n",
    "    output = model(xcs.cuda(), xfs.cuda())\n",
    "    output = torch.sigmoid(output)\n",
    "    test_scores.append(output)\n",
    "    y_true = torch.tensor([y.min(dim=0)[1].item() for y in ys]).cuda()\n",
    "    y_onehot = F.one_hot(y_true, 18).float()\n",
    "    win_flags.append(y_onehot)\n",
    "    odds = torch.stack([torch.cat([odd, 100*torch.ones(18-len(odd))], dim=0) for odd in odds], dim=0)\n",
    "    \n",
    "    odds_list.append(odds)\n",
    "test_scores = torch.cat(test_scores, dim=0)\n",
    "win_flags = torch.cat(win_flags, dim=0)\n",
    "odds_list = torch.cat(odds_list, dim=0).cuda()\n",
    "odds_list = torch.nan_to_num(odds_list)\n",
    "ranking = torch.sort(odds_list, dim=1)[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "e6f6a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n",
      "th 0.7 recovery 85.35714285714285, hit 51.0, cost 112.0, accuracy 0.4553571343421936\n"
     ]
    }
   ],
   "source": [
    "thresh = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for th in thresh:\n",
    "    th = 0.7\n",
    "    gap = (torch.sort(test_scores, dim=1)[0][:, -1] - torch.sort(test_scores, dim=1)[0][:, -2]) > 0.2\n",
    "    gap = gap.unsqueeze(1)\n",
    "    max_score = test_scores.max(dim=1)[0].unsqueeze(1)\n",
    "    buy_flags = (test_scores > th) * gap #* F.one_hot(odds_list.min(dim=1)[1], 18)#* (odds_list > 3)\n",
    "    win = (odds_list * (test_scores >= max_score) * buy_flags * win_flags).sum()\n",
    "    hit = ((test_scores >= max_score) * buy_flags * win_flags).sum()\n",
    "    cost = buy_flags.sum() + 1e-10\n",
    "    print(f'th {th} recovery {win/cost*100}, hit {hit}, cost {cost}, accuracy {hit/cost}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1803f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "a3aff32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0,  0,  0,  0,  5,  3,  0,  2,  0,  0,  4,  0,  0, 10,  0,  0,  1,\n",
       "         0,  1,  1,  2,  5,  0,  0,  0,  0,  0,  0,  1,  3,  2,  1,  3,  1,  7,\n",
       "         0,  0,  7,  0,  4,  0,  0,  0,  2,  4,  3,  2,  4,  0,  1, 11,  2,  0,\n",
       "         4, 11,  1,  1,  7,  0,  0,  0,  0,  0,  0,  0,  5,  3,  0,  6,  3,  5,\n",
       "         0,  0,  1,  5,  7,  0,  3,  3,  2,  8,  0,  0,  2,  0,  2,  1,  4,  1,\n",
       "         0,  2,  0,  3,  3,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0, 15, 14,\n",
       "         1,  4,  1,  1], device='cuda:0')"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(buy_flags)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "c55bbea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  1,  1,  1,  1,  9,  2,  1,  2,  1,  1,  1,  1,  1, 13,  1,  1,  1,\n",
       "         1,  3,  1,  7, 16,  1,  1,  1,  1,  1,  1,  9,  1,  4,  3,  2,  4,  7,\n",
       "         1,  1,  7,  1, 14,  1,  1,  1,  4,  4,  5,  5,  8,  1,  3, 17,  4,  1,\n",
       "         6,  8,  3,  1,  5,  1,  1,  1,  5,  1,  1,  1,  8,  1,  1,  6,  3,  2,\n",
       "         1,  1,  4,  4,  3,  1,  1,  3,  6, 10,  1,  1,  7,  1,  2,  7,  6,  8,\n",
       "         3,  1,  1,  5,  3, 11,  1,  1,  1,  1,  4,  1,  3,  1,  1,  1, 14, 16,\n",
       "         4, 10,  1,  4], device='cuda:0')"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (buy_flags * ranking).flatten()\n",
    "a[a.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "ece8a7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7000, 2.8000, 1.2000, 1.2000, 1.7000, 2.5000, 2.5000, 1.8000, 1.5000,\n",
       "        2.5000, 1.7000, 1.6000, 1.6000, 1.7000, 2.6000, 1.4000, 1.6000, 1.5000,\n",
       "        3.1000, 1.6000, 2.0000, 2.2000, 1.7000, 1.5000, 1.4000, 1.3000, 1.2000,\n",
       "        1.4000, 1.6000, 3.0000, 3.7000, 2.8000, 1.8000, 1.8000, 1.7000, 3.6000,\n",
       "        1.4000, 1.7000, 2.4000, 1.5000, 1.8000, 1.7000, 1.5000, 1.6000, 1.7000,\n",
       "        1.8000, 1.4000, 2.3000, 3.9000, 1.6000, 2.4000, 1.3000, 2.5000, 2.4000,\n",
       "        1.8000, 1.8000, 1.8000, 2.1000, 1.9000, 1.7000, 2.0000, 1.3000, 8.0000,\n",
       "        1.3000, 2.9000, 1.3000, 4.5000, 3.1000, 2.6000, 7.3000, 4.4000, 2.1000,\n",
       "        1.3000, 1.3000, 2.3000, 5.2000, 1.4000, 1.1000, 1.4000, 2.2000, 2.9000,\n",
       "        1.5000, 1.5000, 1.5000, 1.7000, 2.6000, 1.7000, 1.5000, 3.6000, 1.6000,\n",
       "        5.2000, 1.5000, 2.0000, 2.2000, 2.4000, 1.7000, 1.4000, 1.2000, 1.9000,\n",
       "        1.1000, 2.6000, 1.5000, 2.5000, 1.9000, 1.3000, 1.1000, 1.5000, 4.2000,\n",
       "        1.6000, 1.5000, 1.6000, 2.3000], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (buy_flags * odds_list).flatten()\n",
    "b[b.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "aecb6b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  0,  0,  0,  0,  9,  2,  0,  2,  0,  0,  1,  0,  0, 13,  0,  0,  1,\n",
       "         0,  3,  1,  7, 16,  0,  0,  0,  0,  0,  0,  9,  1,  4,  3,  2,  4,  7,\n",
       "         0,  0,  7,  0, 14,  0,  0,  0,  4,  4,  5,  5,  8,  0,  3, 17,  4,  0,\n",
       "         6,  8,  3,  1,  5,  0,  0,  0,  0,  0,  0,  0,  8,  1,  0,  6,  3,  2,\n",
       "         0,  0,  4,  4,  3,  0,  1,  3,  6, 10,  0,  0,  7,  0,  2,  7,  6,  8,\n",
       "         0,  1,  0,  5,  3, 11,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0, 14, 16,\n",
       "         4, 10,  1,  4], device='cuda:0')"
      ]
     },
     "execution_count": 972,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.nonzero()].flatten() * (torch.nonzero(buy_flags)[:, 1] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "eec81cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 5, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.nonzero()].flatten() * (torch.nonzero(buy_flags)[:, 1] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "3cc24147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 8.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        5.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 2.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((a[a.nonzero()].flatten() * (torch.nonzero(buy_flags)[:, 1] == 0)) > 1) * b[b.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2206c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d545ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "98d53262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8000, 1.2000, 1.2000, 1.7000, 1.8000, 2.5000, 1.7000, 1.6000, 1.7000,\n",
       "        1.4000, 1.6000, 3.1000, 1.5000, 1.4000, 1.3000, 1.2000, 1.4000, 1.6000,\n",
       "        1.4000, 1.7000, 1.5000, 1.7000, 1.5000, 1.6000, 1.6000, 2.4000, 1.7000,\n",
       "        2.0000, 1.3000, 8.0000, 1.3000, 2.9000, 1.3000, 2.6000, 1.3000, 1.3000,\n",
       "        1.1000, 1.5000, 1.5000, 2.6000, 5.2000, 2.0000, 1.4000, 1.2000, 1.9000,\n",
       "        1.1000, 1.5000, 2.5000, 1.9000, 1.3000, 1.1000], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (buy_flags * odds_list* win_flags).flatten()\n",
    "a[a.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "20edefb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(95.6000, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(buy_flags * odds_list* win_flags).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "0af3aac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(95.6000, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(odds_list * (test_scores >= max_score) * buy_flags * win_flags).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601de91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edcb8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "38de6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recovery 79.86819871578237, hit 963.0, cost 2959.0, accuracy 0.32544779777526855\n"
     ]
    }
   ],
   "source": [
    "# 1人気の馬\n",
    "buy_flags = F.one_hot(odds_list.min(dim=1)[1], 18)\n",
    "win = (odds_list * buy_flags * win_flags).sum()\n",
    "hit = (buy_flags * win_flags).sum()\n",
    "cost = buy_flags.sum() + 1e-10\n",
    "print(f'recovery {win/cost*100}, hit {hit}, cost {cost}, accuracy {hit/cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b853278b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6789, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(odds_list * buy_flags * win_flags)[:, 0].sum() / (buy_flags * win_flags).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb518d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14a45e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_day(df, tday):\n",
    "    df_test = df[df['date']==tday]\n",
    "    trainval_num = (df['date'] < tday).sum()\n",
    "    val_num = int(trainval_num / 5)\n",
    "    train_num = trainval_num - val_num\n",
    "    while 1:\n",
    "        if df.iloc[train_num-1]['race_num'] == df.iloc[train_num]['race_num']:\n",
    "            train_num += 1\n",
    "        else:\n",
    "            break\n",
    "    df_train = df[:train_num]\n",
    "    df_val = df[train_num:trainval_num]\n",
    "    \n",
    "    keiba_train = KDataset(df_train)\n",
    "    keiba_val = KDataset(df_val)\n",
    "    keiba_test = KDataset(df_test)\n",
    "    \n",
    "    keiba_trainloader = DataLoader(keiba_train, shuffle=True, batch_size=240, collate_fn=keiba_train.collate_fn)\n",
    "    keiba_valloader = DataLoader(keiba_val, shuffle=True, batch_size=240, collate_fn=keiba_val.collate_fn)\n",
    "    keiba_testloader = DataLoader(keiba_test, shuffle=False, batch_size=1, collate_fn=keiba_test.collate_fn)\n",
    "    \n",
    "    model = Transformer(nhead=5, num_layers=10, embedding_dim=embedding_dim)\n",
    "    model.cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        for i, (xcs, xfs, ys, odds) in enumerate(keiba_trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xcs.cuda(), xfs.cuda())\n",
    "            #y_true = torch.tensor([y.min(dim=0)[1] for y in ys])\n",
    "            y_true = torch.stack([torch.cat([(y<=3).long(), torch.zeros(18-len(y))], dim=0) for y in ys], dim=0)\n",
    "            loss = criterion(output, y_true.cuda())\n",
    "            print(f'{i} / {len(keiba_trainloader)} {loss.item()}', end='\\r')\n",
    "            loss.backward()\n",
    "            #print(loss.item())\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        for i, (xcs, xfs, ys, odds) in enumerate(keiba_valloader):\n",
    "            print(f'{i} / {len(keiba_valloader)}', end='\\r')\n",
    "            output = model(xcs.cuda(), xfs.cuda())\n",
    "            #y_true = torch.tensor([y.min(dim=0)[1] for y in ys])\n",
    "            y_true = torch.stack([torch.cat([(y<=3).long(), torch.zeros(18-len(y))], dim=0) for y in ys], dim=0)\n",
    "            loss = criterion(output, y_true.cuda())\n",
    "            val_loss.append(loss)\n",
    "            break\n",
    "        \n",
    "        test_scores = []\n",
    "        win_flags = []\n",
    "        odds_list = []\n",
    "        for i, (xcs, xfs, ys, odds) in enumerate(keiba_testloader):\n",
    "            print(f'{i} / {len(keiba_testloader)}', end='\\r')\n",
    "            output = model(xcs.cuda(), xfs.cuda())\n",
    "            output = torch.sigmoid(output)\n",
    "            test_scores.append(output)\n",
    "            y_true = torch.tensor([y.min(dim=0)[1].item() for y in ys]).cuda()\n",
    "            y_onehot = F.one_hot(y_true, 18).float()\n",
    "            win_flags.append(y_onehot)\n",
    "            odds = torch.stack([torch.cat([odd, torch.zeros(18-len(odd))], dim=0) for odd in odds], dim=0)\n",
    "            odds_list.append(odds)\n",
    "        return test_scores, win_flags, odds_list               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ebe57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2d9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "03f60e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 10\n",
      "1 / 10350 0.39617770910263063\n",
      "2 / 10550 0.41054525971412664\n",
      "3 / 10550 0.38854262232780457\n",
      "4 / 10450 0.39620646834373474\n",
      "5 / 10550 0.40993005037307746\n",
      "6 / 10550 0.40325838327407837\n",
      "7 / 10550 0.41802340745925903\n",
      "8 / 10351 0.39674076437950134\n",
      "9 / 10351 0.45109203457832336\n",
      "22 / 2351 0.39875671267509464\r"
     ]
    }
   ],
   "source": [
    "test_scores, win_flags, odds_list = [], [], []\n",
    "test_from = 10\n",
    "\n",
    "for i, tday in enumerate(np.sort(df['date'].unique()[-test_from:])):\n",
    "    print(f'{i} / {len(np.sort(df[\"date\"].unique()[-test_from:]))}')\n",
    "    s, w, o = test_one_day(df, tday)\n",
    "    test_scores.extend(s)\n",
    "    win_flags.extend(w)\n",
    "    odds_list.extend(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ce74ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = torch.cat(test_scores, dim=0)\n",
    "win_flags = torch.cat(win_flags, dim=0)\n",
    "odds_list = torch.cat(odds_list, dim=0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7b5bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th 0.0 recovery 6.675925925925926, hit 50.0, cost 5400.0\n",
      "th 0.1 recovery 8.446579194001874, hit 50.0, cost 4268.0\n",
      "th 0.2 recovery 19.51900698215671, hit 45.0, cost 1289.0\n",
      "th 0.3 recovery 36.407407407407405, hit 23.0, cost 270.0\n",
      "th 0.4 recovery 43.134328358208954, hit 9.0, cost 67.0\n",
      "th 0.5 recovery 0.0, hit 0.0, cost 5.0\n",
      "th 0.6 recovery 0.0, hit 0.0, cost 1.000000013351432e-10\n",
      "th 0.7 recovery 0.0, hit 0.0, cost 1.000000013351432e-10\n",
      "th 0.8 recovery 0.0, hit 0.0, cost 1.000000013351432e-10\n",
      "th 0.9 recovery 0.0, hit 0.0, cost 1.000000013351432e-10\n"
     ]
    }
   ],
   "source": [
    "thresh = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for th in thresh:\n",
    "    gap = (torch.sort(test_scores, dim=1)[0][:, -1] - torch.sort(test_scores, dim=1)[0][:, -2]) > 0.\n",
    "    gap = gap.unsqueeze(1)\n",
    "    max_score = test_scores.max(dim=1)[0].unsqueeze(1)\n",
    "    buy_flags = (test_scores > th) * gap\n",
    "    win = (odds_list * (test_scores >= max_score) * buy_flags * win_flags).sum()\n",
    "    hit = ((test_scores >= max_score) * buy_flags * win_flags).sum()\n",
    "    cost = buy_flags.sum() + 1e-10\n",
    "    print(f'th {th} recovery {win/cost*100}, hit {hit}, cost {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35d459c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2123, 0.1828, 0.2272,  ..., 0.1513, 0.0420, 0.0420],\n",
       "        [0.1333, 0.1214, 0.1114,  ..., 0.1108, 0.0723, 0.1382],\n",
       "        [0.1124, 0.1278, 0.1118,  ..., 0.3269, 0.0326, 0.0326],\n",
       "        ...,\n",
       "        [0.2358, 0.2683, 0.2689,  ..., 0.0344, 0.0344, 0.0344],\n",
       "        [0.1966, 0.1927, 0.1961,  ..., 0.0569, 0.0569, 0.0569],\n",
       "        [0.2221, 0.2532, 0.1674,  ..., 0.3429, 0.1107, 0.1107]],\n",
       "       device='cuda:0', grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5846bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511cb77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717b2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060437f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2064790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa776039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66c0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba4a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68530175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203f315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
